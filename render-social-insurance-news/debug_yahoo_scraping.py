#!/usr/bin/env python3
"""
Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é–¢é€£æ€§åˆ¤å®šã®å‹•ä½œã‚’è©³ã—ãç¢ºèªã™ã‚‹
"""

import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime

class YahooNewsDebugger:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # æ‹¡å¼µã•ã‚ŒãŸç¤¾ä¼šä¿é™ºé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.relevant_keywords = [
            # åŸºæœ¬çš„ãªç¤¾ä¼šä¿é™ºåˆ¶åº¦
            'å¥åº·ä¿é™º', 'åšç”Ÿå¹´é‡‘', 'å›½æ°‘å¹´é‡‘', 'é›‡ç”¨ä¿é™º', 'åŠ´ç½ä¿é™º', 'ä»‹è­·ä¿é™º',
            'ç¤¾ä¼šä¿é™º', 'è¢«ä¿é™ºè€…', 'ä¿é™ºæ–™', 'å¹´é‡‘', 'åŒ»ç™‚ä¿é™º', 'å¤±æ¥­çµ¦ä»˜',
            'åŠ´åƒç½å®³', 'ä»‹è­·çµ¦ä»˜', 'ä¿é™ºé©ç”¨', 'åˆ¶åº¦æ”¹æ­£', 'æ³•æ”¹æ­£',
            
            # çµ„ç¹”ãƒ»åˆ¶åº¦å
            'å”ä¼šã‘ã‚“ã½', 'å¹´é‡‘æ©Ÿæ§‹', 'ç¤¾åŠ´å£«', 'çµ¦ä»˜é‡‘', 'é©ç”¨æ‹¡å¤§',
            'åšç”ŸåŠ´åƒçœ', 'ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ã‚¯', 'å¹´é‡‘äº‹å‹™æ‰€', 'ç¤¾ä¼šä¿é™ºåŠ´å‹™å£«',
            
            # é–¢é€£ã™ã‚‹ç¤¾ä¼šå•é¡Œãƒ»æ”¿ç­–
            'åŒ»ç™‚è²»', 'é«˜é½¢è€…', 'éšœå®³è€…', 'è‚²å…', 'å‡ºç”£', 'ç™‚é¤Šè²»',
            'æ‰¶é¤Š', 'è³ƒé‡‘', 'åŠ´åƒè€…', 'äº‹æ¥­ä¸»', 'ä¿é™ºåˆ¶åº¦', 'ç¤¾ä¼šä¿éšœ',
            'ç¦ç¥‰', 'åŒ»ç™‚åˆ¶åº¦', 'é€€è·', 'å°±è·', 'è·æ¥­è¨“ç·´',
            'ä¼‘æ¥­è£œå„Ÿ', 'é€šå‹¤ç½å®³', 'æ¥­å‹™ç½å®³', 'è¦ä»‹è­·', 'è¦æ”¯æ´',
            
            # ã‚ˆã‚Šå¹…åºƒã„é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            'åƒãæ–¹æ”¹é©', 'å°‘å­é«˜é½¢åŒ–', 'ãƒã‚¤ãƒŠãƒ³ãƒãƒ¼', 'é›»å­ç”³è«‹',
            'å®šå¹´å»¶é•·', 'éæ­£è¦é›‡ç”¨', 'æ­£ç¤¾å“¡åŒ–', 'DX', 'ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–',
            'æ‰‹ç¶šãç°¡ç´ åŒ–', 'çª“å£', 'ç›¸è«‡', 'ç”³è«‹', 'çµ¦ä»˜',
            'èªå®š', 'å¯©æŸ»', 'æ”¯çµ¦', 'å—çµ¦', 'ç´ä»˜', 'å¾´å'
        ]
    
    def is_social_insurance_relevant_loose(self, title):
        """ç·©å’Œç‰ˆ ç¤¾ä¼šä¿é™ºé–¢é€£åˆ¤å®š"""
        if len(title.strip()) < 5:
            return False
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé–¢ä¿‚ãªã„ã‚‚ã®ï¼‰
        exclude_keywords = [
            'JavaScript', 'Cookie', 'PDF', 'ã‚·ã‚¹ãƒ†ãƒ ', 'ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹',
            'ãƒ–ãƒ©ã‚¦ã‚¶', 'Internet Explorer', 'ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£',
            'ã‚¹ãƒãƒ¼ãƒ„', 'èŠ¸èƒ½', 'ã‚¨ãƒ³ã‚¿ãƒ¡', 'å¤©æ°—', 'å ã„', 'ã‚²ãƒ¼ãƒ ',
            'æ ªä¾¡', 'ç‚ºæ›¿', 'ç«¶é¦¬', 'å®ãã˜', 'ãƒ‘ãƒãƒ³ã‚³'
        ]
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        for exclude in exclude_keywords:
            if exclude in title:
                return False
        
        # é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆ1ã¤ã§ã‚‚å«ã¾ã‚Œã¦ã„ã‚Œã°OKï¼‰
        title_lower = title.lower()
        for keyword in self.relevant_keywords:
            if keyword in title:
                return True
        
        # éƒ¨åˆ†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šç·©ã„æ¡ä»¶ï¼‰
        partial_keywords = [
            'ä¿é™º', 'å¹´é‡‘', 'çµ¦ä»˜', 'åˆ¶åº¦', 'åŠ´åƒ', 'åŒ»ç™‚', 'ç¦ç¥‰',
            'åƒã', 'ä»•äº‹', 'é›‡ç”¨', 'é€€è·', 'å°±è·', 'ç—…æ°—', 'ä»‹è­·',
            'å­è‚²ã¦', 'å‡ºç”£', 'è‚²å…', 'éšœå®³', 'é«˜é½¢', 'ç”³è«‹', 'æ‰‹ç¶šã'
        ]
        
        matched_partials = 0
        for keyword in partial_keywords:
            if keyword in title:
                matched_partials += 1
        
        # 1å€‹ä»¥ä¸Šã®éƒ¨åˆ†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Œã°é–¢é€£ã¨ã™ã‚‹ï¼ˆã‚ˆã‚Šç·©ã„è¨­å®šï¼‰
        if matched_partials >= 1:
            return True
        
        return False
    
    def test_yahoo_search(self, search_terms):
        """Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
        total_found = 0
        total_relevant = 0
        
        for term in search_terms:
            print(f"\nğŸ” æ¤œç´¢èª: '{term}'")
            try:
                search_url = f"https://news.yahoo.co.jp/search?p={term}&ei=UTF-8"
                response = self.session.get(search_url, timeout=30)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ã‚ˆã‚Šå¹…åºƒã„ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’è©¦ã™
                selectors = [
                    'article',
                    'div[class*="sc-"]',
                    'div[class*="newsFeed"]',
                    'li[class*="topics"]',
                    'div.contentMain',
                    '.searchResult li',
                    '.newsList li',
                    '.topicsList li'
                ]
                
                articles = []
                for selector in selectors:
                    found = soup.select(selector)
                    if found:
                        print(f"  ğŸ“„ ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ '{selector}' ã§ {len(found)}ä»¶ç™ºè¦‹")
                        articles = found
                        break
                
                if not articles:
                    # ã‚ˆã‚Šåºƒç¯„å›²ã«ãƒªãƒ³ã‚¯è¦ç´ ã‚’æ¢ã™
                    all_links = soup.find_all('a', href=True)
                    print(f"  ğŸ“„ å…¨ãƒªãƒ³ã‚¯è¦ç´ : {len(all_links)}ä»¶")
                    articles = all_links[:50]  # æœ€åˆã®50ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
                
                found_count = 0
                relevant_count = 0
                
                print(f"  ğŸ“‹ è§£æå¯¾è±¡: {len(articles)}ä»¶")
                
                for i, article in enumerate(articles[:20]):  # æœ€åˆã®20ä»¶ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯
                    try:
                        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡ºï¼ˆè¤‡æ•°ã®æ–¹æ³•ã‚’è©¦è¡Œï¼‰
                        title = None
                        
                        if article.name == 'a':
                            title = article.get_text(strip=True)
                        else:
                            # å­è¦ç´ ã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                            link = article.find('a', href=True)
                            if link:
                                title = link.get_text(strip=True)
                        
                        if not title or len(title) < 10:
                            continue
                        
                        found_count += 1
                        
                        # é–¢é€£æ€§åˆ¤å®šï¼ˆãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ä»˜ãï¼‰
                        is_relevant = self.is_social_insurance_relevant_loose(title)
                        
                        if is_relevant:
                            relevant_count += 1
                            print(f"    âœ… [é–¢é€£] {title[:60]}...")
                        else:
                            print(f"    âŒ [ç„¡é–¢ä¿‚] {title[:60]}...")
                            
                    except Exception as e:
                        print(f"    âš ï¸ è¨˜äº‹è§£æã‚¨ãƒ©ãƒ¼: {e}")
                        continue
                
                print(f"  ğŸ“Š çµæœ: ç™ºè¦‹ {found_count}ä»¶ / é–¢é€£ {relevant_count}ä»¶")
                total_found += found_count
                total_relevant += relevant_count
                
                time.sleep(2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                
            except Exception as e:
                print(f"  âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print(f"\nğŸ“ˆ ç·åˆçµæœ:")
        print(f"   ç·ç™ºè¦‹æ•°: {total_found}ä»¶")
        print(f"   é–¢é€£è¨˜äº‹: {total_relevant}ä»¶")
        print(f"   é–¢é€£ç‡: {(total_relevant/total_found*100):.1f}%" if total_found > 0 else "   é–¢é€£ç‡: N/A")
        
        return total_relevant

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    debugger = YahooNewsDebugger()
    
    print("ğŸ” Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ãƒ‡ãƒãƒƒã‚°é–‹å§‹")
    print("=" * 60)
    
    # æ¤œç´¢èªãƒªã‚¹ãƒˆï¼ˆç¾åœ¨ä½¿ç”¨ã—ã¦ã„ã‚‹ã‚‚ã®ï¼‰
    search_terms = [
        'ç¤¾ä¼šä¿é™º', 'åšç”Ÿå¹´é‡‘', 'å¥åº·ä¿é™º', 'é›‡ç”¨ä¿é™º', 'å¹´é‡‘æ”¹æ­£',
        'ä»‹è­·ä¿é™º', 'åŠ´ç½ä¿é™º', 'å¹´é‡‘åˆ¶åº¦', 'åŒ»ç™‚ä¿é™ºåˆ¶åº¦', 'ä¿é™ºæ–™æ”¹æ­£'
    ]
    
    relevant_count = debugger.test_yahoo_search(search_terms)
    
    print("\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
    if relevant_count < 20:
        print("   - æ¤œç´¢èªã‚’è¿½åŠ ï¼ˆä¾‹ï¼šåƒãæ–¹æ”¹é©ã€ç¤¾ä¼šä¿éšœã€çµ¦ä»˜é‡‘ï¼‰")
        print("   - é–¢é€£æ€§åˆ¤å®šã‚’ã‚ˆã‚Šç·©å’Œ")
        print("   - ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã®æ‹¡å……")
    else:
        print("   - ç¾åœ¨ã®è¨­å®šã§ååˆ†ãªä»¶æ•°ã‚’å–å¾—æ¸ˆã¿")
    
    print(f"\nâ° å®Ÿè¡Œå®Œäº†: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")

if __name__ == "__main__":
    main()